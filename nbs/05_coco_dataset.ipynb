{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c596b417",
   "metadata": {},
   "source": [
    "# COCO\n",
    "> Detail API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "993c3014-d53b-4e67-b4fc-3057eb952dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp coco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdecddc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from avcv._imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76001c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "PYTHON_VERSION = 3\n",
    "\n",
    "\n",
    "class AvCOCO(coco.COCO):\n",
    "    def __init__(self, annotation_file=None, verbose=False):\n",
    "        \"\"\"\n",
    "        Constructor of Microsoft COCO helper class for reading and visualizing annotations.\n",
    "        :param annotation_file (str): location of annotation file\n",
    "        :param image_folder (str): location to the folder that hosts images.\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # load dataset\n",
    "        self.dataset,self.anns,self.cats,self.imgs = dict(),dict(),dict(),dict()\n",
    "        self.imgToAnns, self.catToImgs = defaultdict(list), defaultdict(list)\n",
    "        self.verbose = verbose\n",
    "        if not annotation_file == None:\n",
    "            if verbose:\n",
    "                logger.info('loading annotations into memory...')\n",
    "            tic = time.time()\n",
    "            if isinstance(annotation_file, str):\n",
    "                with open(annotation_file, 'r') as f:\n",
    "                    dataset = json.load(f)\n",
    "            else:\n",
    "                dataset = annotation_file\n",
    "            assert type(dataset)==dict, 'annotation file format {} not supported'.format(type(dataset))\n",
    "            if verbose:\n",
    "                logger.info('Done (t={:0.2f}s)'.format(time.time()- tic))\n",
    "            self.dataset = dataset\n",
    "            self.createIndex()\n",
    "            \n",
    "            \n",
    "    def createIndex(self):\n",
    "        # create index\n",
    "        if self.verbose:\n",
    "            logger.info('creating index...')\n",
    "        anns, cats, imgs = {}, {}, {}\n",
    "        imgToAnns,catToImgs = defaultdict(list),defaultdict(list)\n",
    "        if 'annotations' in self.dataset:\n",
    "            for ann in self.dataset['annotations']:\n",
    "                imgToAnns[ann['image_id']].append(ann)\n",
    "                anns[ann['id']] = ann\n",
    "\n",
    "        if 'images' in self.dataset:\n",
    "            for img in self.dataset['images']:\n",
    "                imgs[img['id']] = img\n",
    "\n",
    "        if 'categories' in self.dataset:\n",
    "            for cat in self.dataset['categories']:\n",
    "                cats[cat['id']] = cat\n",
    "\n",
    "        if 'annotations' in self.dataset and 'categories' in self.dataset:\n",
    "            for ann in self.dataset['annotations']:\n",
    "                catToImgs[ann['category_id']].append(ann['image_id'])\n",
    "        if self.verbose:\n",
    "            logger.info('index created!')\n",
    "\n",
    "        # create class members\n",
    "        self.anns = anns\n",
    "        self.imgToAnns = imgToAnns\n",
    "        self.catToImgs = catToImgs\n",
    "        self.imgs = imgs\n",
    "        self.cats = cats\n",
    "\n",
    "    def loadRes(self, resFile):\n",
    "        \"\"\"\n",
    "        Load result file and return a result api object.\n",
    "        :param   resFile (str)     : file name of result file\n",
    "        :return: res (obj)         : result api object\n",
    "        \"\"\"\n",
    "        res = coco.COCO()\n",
    "        res.dataset['images'] = [img for img in self.dataset['images']]\n",
    "        if self.verbose:\n",
    "            logger.info('Loading and preparing results...')\n",
    "        tic = time.time()\n",
    "        if type(resFile) == str or (PYTHON_VERSION == 2 and type(resFile) == unicode):\n",
    "            with open(resFile) as f:\n",
    "                anns = json.load(f)\n",
    "        elif type(resFile) == np.ndarray:\n",
    "            anns = self.loadNumpyAnnotations(resFile)\n",
    "        else:\n",
    "            anns = resFile\n",
    "        assert type(anns) == list, 'results in not an array of objects'\n",
    "        annsImgIds = [ann['image_id'] for ann in anns]\n",
    "        assert set(annsImgIds) == (set(annsImgIds) & set(self.getImgIds())), \\\n",
    "               'Results do not correspond to current coco set'\n",
    "        if len(anns):\n",
    "            if 'caption' in anns[0]:\n",
    "                imgIds = set([img['id'] for img in res.dataset['images']]) & set([ann['image_id'] for ann in anns])\n",
    "                res.dataset['images'] = [img for img in res.dataset['images'] if img['id'] in imgIds]\n",
    "                for id, ann in enumerate(anns):\n",
    "                    ann['id'] = id+1\n",
    "            elif 'bbox' in anns[0] and not anns[0]['bbox'] == []:\n",
    "                res.dataset['categories'] = copy.deepcopy(self.dataset['categories'])\n",
    "                for id, ann in enumerate(anns):\n",
    "                    bb = ann['bbox']\n",
    "                    x1, x2, y1, y2 = [bb[0], bb[0]+bb[2], bb[1], bb[1]+bb[3]]\n",
    "                    if not 'segmentation' in ann:\n",
    "                        ann['segmentation'] = [[x1, y1, x1, y2, x2, y2, x2, y1]]\n",
    "                    ann['area'] = bb[2]*bb[3]\n",
    "                    ann['id'] = id+1\n",
    "                    ann['iscrowd'] = 0\n",
    "            elif 'segmentation' in anns[0]:\n",
    "                res.dataset['categories'] = copy.deepcopy(self.dataset['categories'])\n",
    "                for id, ann in enumerate(anns):\n",
    "                    # now only support compressed RLE format as segmentation results\n",
    "                    ann['area'] = maskUtils.area(ann['segmentation'])\n",
    "                    if not 'bbox' in ann:\n",
    "                        ann['bbox'] = maskUtils.toBbox(ann['segmentation'])\n",
    "                    ann['id'] = id+1\n",
    "                    ann['iscrowd'] = 0\n",
    "            elif 'keypoints' in anns[0]:\n",
    "                res.dataset['categories'] = copy.deepcopy(self.dataset['categories'])\n",
    "                for id, ann in enumerate(anns):\n",
    "                    s = ann['keypoints']\n",
    "                    x = s[0::3]\n",
    "                    y = s[1::3]\n",
    "                    x0,x1,y0,y1 = np.min(x), np.max(x), np.min(y), np.max(y)\n",
    "                    ann['area'] = (x1-x0)*(y1-y0)\n",
    "                    ann['id'] = id + 1\n",
    "                    ann['bbox'] = [x0,y0,x1-x0,y1-y0]\n",
    "            if self.verbose:\n",
    "                logger.info('DONE (t={:0.2f}s)'.format(time.time()- tic))\n",
    "\n",
    "        res.dataset['annotations'] = anns\n",
    "        res.createIndex()\n",
    "        return res        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698bb1ce-c2da-4715-a897-0daae2b7582d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0add8d1a-ba05-4a11-99b1-c3139e0a327b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from avcv.visualize import bbox_visualize, show as av_show\n",
    "#import COCOeval\n",
    "\n",
    "\n",
    "class CocoDataset:\n",
    "    def __init__(self, gt, img_dir=None, pred=None, verbose=False):\n",
    "        if img_dir is None:\n",
    "            assert isinstance(gt, str) and '/annotations/' in gt\n",
    "            img_dir = gt.split('/annotations/')[0]+'/images'\n",
    "            if verbose:\n",
    "                logger.warning(f'Img dir is not set, set to :{img_dir}')\n",
    "            # assert osp.isdir(img_dir)\n",
    "            \n",
    "        if isinstance(gt, coco.COCO):\n",
    "            gt = gt.dataset\n",
    "        self.gt = AvCOCO(gt, verbose=verbose)\n",
    "\n",
    "        if isinstance(pred, str):\n",
    "            pred = mmcv.load(pred)\n",
    "\n",
    "        self.pred = self.gt.loadRes(pred) if pred is not None else None\n",
    "\n",
    "        self.img_dir = img_dir\n",
    "        self.img_ids = [_['id'] for _ in self.gt.imgs.values()]\n",
    "\n",
    "    def imread(self, img_id, channel_order='bgr'):\n",
    "        im = self.gt.imgs[img_id]\n",
    "        img_path = osp.abspath(osp.join(self.img_dir,im['file_name']))\n",
    "        assert osp.exists(img_path), img_path\n",
    "        return mmcv.imread(img_path, channel_order=channel_order)\n",
    "\n",
    "    def visualize(self, img_id=None,  mode='gt', dpi=100, \n",
    "        show=False, anns=None, color='green', img=None, score_thr=0.3, box_color=None):\n",
    "        if img_id is None:\n",
    "            img_id = np.random.choice(self.img_ids)\n",
    "            logger.info(f'Random visualize img_id={img_id}')\n",
    "        if img is None:\n",
    "            img= self.imread(img_id)\n",
    "\n",
    "        if mode=='pred':\n",
    "            assert self.pred is not None\n",
    "\n",
    "        CLASSES = {cat_id:cat['name'] for cat_id, cat in self.gt.cats.items()}\n",
    "        im = self.gt.imgs[img_id]\n",
    "        source = self.pred if mode == 'pred' else self.gt\n",
    "\n",
    "        if anns is None:\n",
    "            anns  = source.loadAnns(source.getAnnIds(im['id']))\n",
    "\n",
    "        bboxes = []\n",
    "        lables = []\n",
    "        scores = []\n",
    "        for ann in anns:\n",
    "            x1,y1,w,h = [int(_) for _ in ann['bbox']]\n",
    "            x2 = x1+w\n",
    "            y2 = y1+h\n",
    "            scores.append(ann.get('score', 1))\n",
    "            bboxes.append([x1,y1,x2,y2])\n",
    "            lables.append(ann['category_id'])\n",
    "\n",
    "        bboxes = np.array(bboxes)\n",
    "        lables = np.array(lables)\n",
    "\n",
    "        if len(bboxes):\n",
    "            \n",
    "            img = bbox_visualize(img, bboxes, scores, lables, score_thr, CLASSES, box_color=box_color)\n",
    "#             img = mmcv.visualization.imshow_det_bboxes(img, bboxes, \n",
    "#                 lables, CLASSES, show=False, bbox_color=color, text_color=color, \n",
    "#                 score_thr=score_thr)\n",
    "        if show:\n",
    "            av_show(img[...,::-1], dpi=dpi)\n",
    "        return img\n",
    "\n",
    "    def load_anns(self, img_id, source=None):\n",
    "        if source is None:\n",
    "            source = self.gt\n",
    "        anns = source.loadAnns(source.getAnnIds(img_id))\n",
    "        return anns\n",
    "\n",
    "    def evaluate(self, *args, **kwargs):\n",
    "        from pycocotools.cocoeval import COCOeval\n",
    "        cocoEval = COCOeval(self.gt, self.pred, 'bbox')\n",
    "        cocoEval.evaluate()\n",
    "        cocoEval.accumulate()\n",
    "        cocoEval.summarize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed36b09-326f-479b-9fce-5c0dc9a729cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e82dcdb-4a14-408d-b1b9-79e2ec4d09ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/data/ActionObjects/LabeledVersionPng/annotations/val.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#| hide\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m cc \u001b[39m=\u001b[39m CocoDataset(\u001b[39m'\u001b[39;49m\u001b[39m/data/ActionObjects/LabeledVersionPng/annotations/val.json\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      3\u001b[0m cc\u001b[39m.\u001b[39mvisualize(show\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 15\u001b[0m, in \u001b[0;36mCocoDataset.__init__\u001b[0;34m(self, gt, img_dir, pred, verbose)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(gt, coco\u001b[39m.\u001b[39mCOCO):\n\u001b[1;32m     14\u001b[0m     gt \u001b[39m=\u001b[39m gt\u001b[39m.\u001b[39mdataset\n\u001b[0;32m---> 15\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgt \u001b[39m=\u001b[39m AvCOCO(gt, verbose\u001b[39m=\u001b[39;49mverbose)\n\u001b[1;32m     17\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(pred, \u001b[39mstr\u001b[39m):\n\u001b[1;32m     18\u001b[0m     pred \u001b[39m=\u001b[39m mmcv\u001b[39m.\u001b[39mload(pred)\n",
      "Cell \u001b[0;32mIn[3], line 22\u001b[0m, in \u001b[0;36mAvCOCO.__init__\u001b[0;34m(self, annotation_file, verbose)\u001b[0m\n\u001b[1;32m     20\u001b[0m tic \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m     21\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(annotation_file, \u001b[39mstr\u001b[39m):\n\u001b[0;32m---> 22\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(annotation_file, \u001b[39m'\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m     23\u001b[0m         dataset \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(f)\n\u001b[1;32m     24\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/pt2/lib/python3.8/site-packages/IPython/core/interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[1;32m    276\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    277\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    279\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m     )\n\u001b[0;32m--> 282\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/data/ActionObjects/LabeledVersionPng/annotations/val.json'"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "cc = CocoDataset('/data/ActionObjects/LabeledVersionPng/annotations/val.json')\n",
    "cc.visualize(show=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d43b1f",
   "metadata": {},
   "source": [
    "### BBox utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a8c76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_bboxes(anns,category_ids,\n",
    "               mode='xywh',\n",
    "               dtype=np.float32,\n",
    "               score_thr=None, with_score=False):\n",
    "    bboxes = []\n",
    "    for ann in anns:\n",
    "        if category_ids is not None and  not ann['category_id'] in category_ids: continue\n",
    "        if score_thr is not None and ann.get('score', False):\n",
    "            if ann['score'] < score_thr:\n",
    "                continue\n",
    "        x, y, w, h = ann['bbox']\n",
    "        \n",
    "        score = ann.get('score', 1)\n",
    "        if mode == 'xywh':\n",
    "            bboxes.append([x, y, w, h, score])\n",
    "        elif mode == 'xyxy':\n",
    "            bboxes.append([x, y, x + w, y + h, score])\n",
    "        elif mode == 'cxcywh':\n",
    "            cx = x + w / 2\n",
    "            cy = y + h / 2\n",
    "            bboxes.append([cx, cy, w, h, score])\n",
    "        else:\n",
    "            raise NotImplemented\n",
    "    bboxes = np.array(bboxes).reshape([-1, 5])\n",
    "    if not with_score:\n",
    "        bboxes = bboxes[:,:4]\n",
    "        \n",
    "    if dtype is not None:\n",
    "        bboxes = bboxes.astype(dtype)\n",
    "    return bboxes\n",
    "\n",
    "\n",
    "def get_overlap_rate(boxA, boxB):\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "    iou = interArea / float(boxAArea)\n",
    "    return iou\n",
    "\n",
    "\n",
    "def bbox_expand(bb, im_h, im_w, r=1.25):\n",
    "    x,y,w,h = bb\n",
    "    cx = x+w/2\n",
    "    cy = y+h/2\n",
    "    h*=r\n",
    "    w*=r\n",
    "    \n",
    "    x1 = cx-w/2\n",
    "    y1 = cy-h/2\n",
    "    x2 = x1+w\n",
    "    y2 = y1+h\n",
    "    \n",
    "    x1 = max(0, x1)\n",
    "    y1 = max(0, y1)\n",
    "    x2 = min(im_w, x2)\n",
    "    y2 = min(im_h, y2)\n",
    "    \n",
    "    return x1, y1, x2-x1, y2-y1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9517518",
   "metadata": {},
   "source": [
    "## DiagnoseCoco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecd78cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DiagnoseCoco(CocoDataset):\n",
    "    COLORS = dict(\n",
    "        TP=(0, 255, 0),\n",
    "        FN=(0, 0, 255), # Undetected GT\n",
    "        FP=(0,255,255), # Wrong detection\n",
    "    )\n",
    "\n",
    "    def find_false_samples(self, img_id, score_thr=0.05, visualize=True):\n",
    "        assert self.gt is not None\n",
    "        assert self.pred is not None\n",
    "        pred_anns = [ann for ann in self.pred.loadAnns(self.pred.getAnnIds(img_id)) if ann['score']>score_thr]\n",
    "        gt_anns = self.gt.loadAnns(self.gt.getAnnIds(img_id))\n",
    "\n",
    "        pred_bboxes = get_bboxes(pred_anns,None , mode='xyxy')\n",
    "\n",
    "        gt_bboxes = get_bboxes(gt_anns, None,mode='xyxy')\n",
    "        with torch.no_grad():\n",
    "            ious = bbox_overlaps(pred_bboxes, gt_bboxes).cpu().numpy()\n",
    "        mapping_gt_pred = np.where(ious>0)\n",
    "\n",
    "        result = dict(tp=[], fn=[], fp=[])\n",
    "\n",
    "        gt_ids = list(range(len(gt_anns)))\n",
    "        pred_ids = list(range(len(pred_anns)))\n",
    "        for pred_id, gt_id in zip(*mapping_gt_pred):\n",
    "            if gt_anns[gt_id]['category_id'] == pred_anns[pred_id]['category_id']:\n",
    "                result['tp'].append(pred_anns[pred_id])\n",
    "                if gt_id in gt_ids:\n",
    "                    gt_ids.remove(gt_id)\n",
    "                if pred_id in pred_ids:\n",
    "                    pred_ids.remove(pred_id)\n",
    "\n",
    "\n",
    "        result['fp'] = [pred_anns[i] for i in  pred_ids]\n",
    "        result['fn'] = [gt_anns[i] for i in gt_ids]\n",
    "        if visualize:\n",
    "            vis_img = self.visualize(img_id, anns=result['fn'], color=self.COLORS['FN'], show=False, box_color=self.COLORS['FN'])\n",
    "            vis_img = self.visualize(img_id,  anns=result['tp'],img=vis_img, show=False,box_color=self.COLORS['TP'])\n",
    "            vis_img = self.visualize(img_id, anns=result['fp'], dpi=150,color=self.COLORS['FP'], show=False,\n",
    "                                     img=vis_img, box_color=self.COLORS['FP'])\n",
    "            vis_img = vis_img[...,::-1].copy()\n",
    "            result['vis_img'] = vis_img\n",
    "        return result\n",
    "    \n",
    "    def imshow(self, img_id, score_thr=0.05, **show_kwargs):\n",
    "        img = self.find_false_samples(img_id, score_thr)['vis_img']\n",
    "        show(img, **show_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e909ae4f",
   "metadata": {},
   "source": [
    "# Utils\n",
    "## Video To Coco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086617bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _f(p):\n",
    "    img = mmcv.imread(p)\n",
    "    mmcv.imwrite(img, p.replace('.png', '.jpg'))\n",
    "    os.remove(p)\n",
    "    \n",
    "def to_jpg(img_dir):\n",
    "    paths = glob(osp.join(img_dir, '*.png'))\n",
    "    logger.info(f'Converting folder {img_dir} to jpg...')\n",
    "    with Pool(10) as p:\n",
    "        it = p.imap(_f, paths)\n",
    "        total = len(paths)\n",
    "        r = list(tqdm(it, total=total))\n",
    "\n",
    "def video_to_coco(\n",
    "    input_video,\n",
    "    test_json,\n",
    "    output_dir=None,\n",
    "    skip=1,\n",
    "    rescale=None,\n",
    "    recursive=False,\n",
    "    min_is_done_extracted_ratio=.7,\n",
    "):\n",
    "\n",
    "    assert os.path.exists(input_video), f'{input_video} does not exist'\n",
    "    try:\n",
    "        fps = mmcv.VideoReader(input_video).fps\n",
    "    except:\n",
    "        fps = None\n",
    "        \n",
    "    def path2image(path, root_dir):\n",
    "        w, h = Image.open(path).size\n",
    "        name = path.replace(root_dir, '')\n",
    "        if name.startswith('/'):\n",
    "            name = name[1:]\n",
    "        return dict(\n",
    "            file_name=name, height=h, width=w\n",
    "        )\n",
    "    \n",
    "\n",
    "    if output_dir is None:\n",
    "        name  = get_name(input_video) if not osp.isdir(input_video) else \\\n",
    "            os.path.normpath(input_video).split('/')[-1]\n",
    "        output_dir = osp.join('.cache/video_to_coco', name)\n",
    "        logger.info(f'Set output dir to->{output_dir}')\n",
    "\n",
    "    image_out_dir = osp.join(output_dir, 'images')\n",
    "\n",
    "    image_dir_name = osp.normpath(image_out_dir).split('/')[-1]\n",
    "    path_out_json = osp.join(output_dir, f'annotations/{image_dir_name}.json')\n",
    "\n",
    "    mmcv.mkdir_or_exist(osp.dirname(path_out_json))\n",
    "\n",
    "    source_type = 'dir' if osp.isdir(input_video) else 'video'\n",
    "    \n",
    "    if not osp.isdir(input_video): # IF VIDEO => EXTRACT IMAGES to image_out_dir\n",
    "        mmcv.mkdir_or_exist(image_out_dir)\n",
    "        video = mmcv.VideoReader(input_video)\n",
    "        \n",
    "\n",
    "        if rescale is not None:\n",
    "            _im = mmcv.imrescale(video[0], rescale)\n",
    "            im_h, im_w = _im.shape[:2]#int(rescale*im_h), int(rescale*im_w)\n",
    "        else:\n",
    "            im_h, im_w = video[0].shape[:2]\n",
    "        num_found_imgs = len(glob(osp.join(image_out_dir, '*.jpg')))\n",
    "        is_done_extracted = (num_found_imgs / len(video)) > min_is_done_extracted_ratio\n",
    "        if not num_found_imgs  == len(video):\n",
    "            logger.warning(f'Differ num of extracted images and video len {num_found_imgs=}, {len(video)=}, {is_done_extracted=}')\n",
    "        \n",
    "        \n",
    "        if not is_done_extracted:\n",
    "            mmcv.mkdir_or_exist(image_out_dir)\n",
    "            cmd = f\"ffmpeg  -i {input_video} -s {im_w}x{im_h} {image_out_dir}/%06d.png\"\n",
    "            logger.info(f'Running command: {cmd}')\n",
    "            os.system(cmd)\n",
    "            to_jpg(image_out_dir)\n",
    "        else:\n",
    "            logger.info('Skip extracting video')\n",
    "        \n",
    "    else:\n",
    "        # IF FOLDER THEN CREATE SYMLINK\n",
    "        logger.info(f'Symn link {input_video}-> {image_out_dir}')\n",
    "        os.symlink(osp.abspath(input_video), osp.abspath(image_out_dir))\n",
    "        \n",
    "    paths = list(sorted(glob(osp.join(image_out_dir, '*.jpg'), recursive=recursive)))\n",
    "    paths += list(sorted(glob(osp.join(image_out_dir, '*.png'), recursive=recursive)))\n",
    "    out_dict = dict(images=[], annotations=[], meta=dict(fps=fps),\n",
    "                    categories=mmcv.load(test_json)['categories'])\n",
    "    out_dict['images'] = list(\n",
    "        map(partial(path2image, root_dir=image_out_dir), paths))\n",
    "\n",
    "    for i, image in enumerate(out_dict['images']):\n",
    "        image['id'] = i\n",
    "    mmcv.dump(out_dict, path_out_json)\n",
    "    return os.path.normpath(path_out_json), os.path.normpath(image_out_dir)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9576cf6-7034-4325-ad5e-7313784fb8d6",
   "metadata": {},
   "source": [
    "# CocoUtils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44889d7-80f2-48aa-982f-f5a52b847c18",
   "metadata": {},
   "source": [
    "## concat_coco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515cf61b-2c30-41a5-943f-9d6128a507f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def split_coco(coco, train_ratio=0.85, seed=0):\n",
    "    if isinstance(coco, dict):\n",
    "        coco = AvCOCO(coco)\n",
    "    ids = list(coco.imgs.keys())\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(ids)\n",
    "    train_n = int(len(ids)*train_ratio)\n",
    "    train_ids = ids[:train_n]\n",
    "    test_ids = ids[train_n:]\n",
    "    logger.info('Spliting ratio {} -> {} training and {} testing'.format(train_ratio, len(train_ids), len(test_ids)))\n",
    "    \n",
    "    # train_ds = coco.dataset.copy()\n",
    "    # val_ds = coco.dataset.copy()\n",
    "    def get_ds(ids):\n",
    "        out = dict(categories=coco.dataset['categories'], images=[], annotations=[])\n",
    "        for img_id in ids:\n",
    "            out['images'].append(coco.imgs[img_id])\n",
    "            out['annotations'].extend(coco.imgToAnns[img_id])\n",
    "        return out\n",
    "    return get_ds(train_ids), get_ds(test_ids)\n",
    "\n",
    "\n",
    "def concat_coco(datasets, new_root, name=None, cat_name2id=None, categories=None, strict_image_path=True, identical_cat_name=True):\n",
    "    \"\"\"\n",
    "        Example:\n",
    "            concat_coco([\n",
    "                (train_ds_1, '/data/full-version-vip-pro/DMS_DB_090922/'),\n",
    "                (train_ds_2, '/data/DMS_Behavior_Detection/merge-phone-cigaret-food/images'),\n",
    "\n",
    "            ], '/data/face_food_concat/', 'train');\n",
    "        \"\"\"\n",
    "    # If datasets if a list of string\n",
    "    if isinstance(datasets[0], str):\n",
    "        inputs = []\n",
    "        # for j in datasets:\n",
    "        def f(j):\n",
    "            cc = CocoDataset(j)\n",
    "            return (cc.gt.dataset, cc.img_dir)\n",
    "        from avcv.all import multi_thread\n",
    "        datasets = multi_thread(f, datasets)\n",
    "            \n",
    "    if cat_name2id is None:\n",
    "        if identical_cat_name:\n",
    "            av_coco = AvCOCO(datasets[0][0])\n",
    "            cat_name2id = {cat['name']:cat['id'] for cat in av_coco.cats.values()}\n",
    "        else:\n",
    "            all_cat_name = []\n",
    "            for dataset in datasets:\n",
    "                av_coco = AvCOCO(dataset[0])\n",
    "                all_cat_name.extend(\n",
    "                    [cat['name'].lower() for cat in av_coco.cats.values()])\n",
    "\n",
    "            all_cat_name = list(set(all_cat_name))\n",
    "            cat_name2id = {name: i + 1 for i, name in enumerate(all_cat_name)}\n",
    "        print(f'cat_name2id={cat_name2id}')\n",
    "\n",
    "    mmcv.mkdir_or_exist(osp.join(new_root, 'annotations'))\n",
    "    out_concat = dict(images=[],\n",
    "                      annotations=[],\n",
    "                      categories=[\n",
    "                          dict(name=name, id=id)\n",
    "                          for name, id in cat_name2id.items()\n",
    "                      ] if categories is None else categories)\n",
    "    CACHE_IMAGE_PATH2ID = {}\n",
    "    def get_image_id(image_path):\n",
    "        image_path = osp.abspath(image_path)\n",
    "        if not image_path in CACHE_IMAGE_PATH2ID:\n",
    "            CACHE_IMAGE_PATH2ID[image_path] = len(CACHE_IMAGE_PATH2ID)+1\n",
    "            \n",
    "        return CACHE_IMAGE_PATH2ID[image_path]\n",
    "        \n",
    "    added_image_ids = set()\n",
    "    \n",
    "    for i, inp in enumerate(datasets):\n",
    "        if not isinstance(inp, tuple):\n",
    "            datasets[i] = (inp, inp.split('/annotations/')[0]+'/images')\n",
    "    \n",
    "    for json_path, old_img_dir in datasets:\n",
    "\n",
    "        if isinstance(json_path, str) or isinstance(json_path, dict):\n",
    "            dataset = AvCOCO(json_path)\n",
    "        else :\n",
    "            dataset = json_path\n",
    "        for img_id in dataset.imgs:\n",
    "            image = dataset.imgs[img_id]\n",
    "            anns = dataset.imgToAnns[\n",
    "                image['id']] if img_id in dataset.imgToAnns else []\n",
    "\n",
    "            old_path = osp.join(old_img_dir, image['file_name'])\n",
    "            old_path = osp.abspath(old_path)\n",
    "            if strict_image_path:\n",
    "                assert osp.exists(old_path), old_path\n",
    "            image['file_name'] = osp.relpath(old_path,\n",
    "                                             osp.join(new_root, 'images'))\n",
    "            \n",
    "            image['id'] = get_image_id(old_path)\n",
    "            for ann in anns:\n",
    "                cat_name = dataset.cats[ann['category_id']]['name']\n",
    "                ann['category_id'] = cat_name2id[cat_name.lower()]\n",
    "                ann['image_id'] = image['id']\n",
    "                w, h = ann['bbox'][-2:]\n",
    "                ann['area'] = w * h\n",
    "                ann['id'] = len(out_concat['annotations'])\n",
    "\n",
    "                out_concat['annotations'].append(ann)\n",
    "                \n",
    "            if not image['id'] in added_image_ids:\n",
    "                valid_classes = set([cat['name'] for cat in dataset.cats.values()]) if not 'pred_' in json_path else None\n",
    "                image['valid_classes'] = valid_classes\n",
    "                out_concat['images'].append(image)\n",
    "                added_image_ids.add(image['id'])\n",
    "\n",
    "    if name is not None:\n",
    "        out_json_path = osp.join(new_root, f'annotations/{name}.json')\n",
    "        logger.info('Annotation is saved to: {}', out_json_path)\n",
    "        check_save_coco_dict(out_concat)\n",
    "        mmcv.dump(out_concat, out_json_path)\n",
    "    # Summary num of images, annotations and categories\n",
    "    logger.info('Summary:'\n",
    "    ' {} images, {} annotations'.format(len(out_concat['images']), out_concat['annotations'])\n",
    "    )\n",
    "    return out_concat\n",
    "\n",
    "\n",
    "def check_save_coco_dict(data):\n",
    "    def check_duplicated_id(name):\n",
    "        ids = set()\n",
    "        for item in data[name]:\n",
    "            if not item['id'] in ids:\n",
    "                ids.add(item['id'])\n",
    "            else:\n",
    "                print(f'{name}, Id: {id} is duplicated, item: {item}')\n",
    "                return False\n",
    "        return True\n",
    "    if check_duplicated_id('images') and check_duplicated_id('annotations') and check_duplicated_id('categories'):\n",
    "        print('This dict is cocoly safe')\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def extract_coco(coco, img_ids):\n",
    "    if isinstance(coco, dict) or isinstance(coco, str):\n",
    "        coco = AvCOCO(coco)\n",
    "    imgs = coco.loadImgs(img_ids)\n",
    "    anns = coco.loadAnns(coco.getAnnIds(img_ids))\n",
    "    return dict(images=imgs, annotations=anns, categories=coco.dataset['categories'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078f0fa8",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5122728e",
   "metadata": {},
   "source": [
    "## CLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5768397",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@call_parse\n",
    "def v2c(input_video: Param(\"path to video\", str),\n",
    "        test_json: Param(\"path to annotation json path, to get the category\", str),\n",
    "        output_dir: Param(\"\", str) = None,\n",
    "        skip: Param(\"\", int) = 1,        rescale: Param(\"\", int) = None, recursive: Param(\"Images recursive\", bool)=False\n",
    "        ):\n",
    "    return video_to_coco(input_video, test_json, output_dir, skip, rescale=rescale, recursive=recursive)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0beb94f5-ad61-44f9-962a-97d318d8670f",
   "metadata": {},
   "source": [
    "# BUILD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc175984",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nbdev_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd53adf-85e5-4b97-9bc9-8193dd7ba612",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5845ed4-5a09-4056-86ec-9c0d1943d0b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987247aa-8489-466f-a146-f463327765d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15 (default, Nov 24 2022, 15:19:38) \n[GCC 11.2.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "b29e17ee5096b60a53ce9c3feb467b82c2092c5bf871e20c52f454151317a987"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
