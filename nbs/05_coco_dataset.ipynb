{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9d051c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp coco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a973ca1c-0b54-4740-9c6a-264c72c93ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c596b417",
   "metadata": {},
   "source": [
    "# COCO\n",
    "> Detail API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdecddc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "import json\n",
    "import torch\n",
    "import os\n",
    "import os.path as osp\n",
    "import shutil\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mmcv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from fastcore.script import *\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "from pycocotools.coco import COCO\n",
    "from tqdm import tqdm\n",
    "from avcv.visualize import show as av_show\n",
    "from avcv.visualize import bbox_visualize\n",
    "from loguru import logger\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76001c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "PYTHON_VERSION = 3\n",
    "class AvCOCO(COCO):\n",
    "    def __init__(self, annotation_file=None, verbose=False):\n",
    "        \"\"\"\n",
    "        Constructor of Microsoft COCO helper class for reading and visualizing annotations.\n",
    "        :param annotation_file (str): location of annotation file\n",
    "        :param image_folder (str): location to the folder that hosts images.\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # load dataset\n",
    "        self.dataset,self.anns,self.cats,self.imgs = dict(),dict(),dict(),dict()\n",
    "        self.imgToAnns, self.catToImgs = defaultdict(list), defaultdict(list)\n",
    "        self.verbose = verbose\n",
    "        if not annotation_file == None:\n",
    "            if verbose:\n",
    "                logger.info('loading annotations into memory...')\n",
    "            tic = time.time()\n",
    "            if isinstance(annotation_file, str):\n",
    "                with open(annotation_file, 'r') as f:\n",
    "                    dataset = json.load(f)\n",
    "            else:\n",
    "                dataset = annotation_file\n",
    "            assert type(dataset)==dict, 'annotation file format {} not supported'.format(type(dataset))\n",
    "            if verbose:\n",
    "                logger.info('Done (t={:0.2f}s)'.format(time.time()- tic))\n",
    "            self.dataset = dataset\n",
    "            self.createIndex()\n",
    "            \n",
    "            \n",
    "    def createIndex(self):\n",
    "        # create index\n",
    "        if self.verbose:\n",
    "            logger.info('creating index...')\n",
    "        anns, cats, imgs = {}, {}, {}\n",
    "        imgToAnns,catToImgs = defaultdict(list),defaultdict(list)\n",
    "        if 'annotations' in self.dataset:\n",
    "            for ann in self.dataset['annotations']:\n",
    "                imgToAnns[ann['image_id']].append(ann)\n",
    "                anns[ann['id']] = ann\n",
    "\n",
    "        if 'images' in self.dataset:\n",
    "            for img in self.dataset['images']:\n",
    "                imgs[img['id']] = img\n",
    "\n",
    "        if 'categories' in self.dataset:\n",
    "            for cat in self.dataset['categories']:\n",
    "                cats[cat['id']] = cat\n",
    "\n",
    "        if 'annotations' in self.dataset and 'categories' in self.dataset:\n",
    "            for ann in self.dataset['annotations']:\n",
    "                catToImgs[ann['category_id']].append(ann['image_id'])\n",
    "        if self.verbose:\n",
    "            logger.info('index created!')\n",
    "\n",
    "        # create class members\n",
    "        self.anns = anns\n",
    "        self.imgToAnns = imgToAnns\n",
    "        self.catToImgs = catToImgs\n",
    "        self.imgs = imgs\n",
    "        self.cats = cats\n",
    "\n",
    "    def loadRes(self, resFile):\n",
    "        \"\"\"\n",
    "        Load result file and return a result api object.\n",
    "        :param   resFile (str)     : file name of result file\n",
    "        :return: res (obj)         : result api object\n",
    "        \"\"\"\n",
    "        res = COCO()\n",
    "        res.dataset['images'] = [img for img in self.dataset['images']]\n",
    "        if self.verbose:\n",
    "            logger.info('Loading and preparing results...')\n",
    "        tic = time.time()\n",
    "        if type(resFile) == str or (PYTHON_VERSION == 2 and type(resFile) == unicode):\n",
    "            with open(resFile) as f:\n",
    "                anns = json.load(f)\n",
    "        elif type(resFile) == np.ndarray:\n",
    "            anns = self.loadNumpyAnnotations(resFile)\n",
    "        else:\n",
    "            anns = resFile\n",
    "        assert type(anns) == list, 'results in not an array of objects'\n",
    "        annsImgIds = [ann['image_id'] for ann in anns]\n",
    "        assert set(annsImgIds) == (set(annsImgIds) & set(self.getImgIds())), \\\n",
    "               'Results do not correspond to current coco set'\n",
    "        if 'caption' in anns[0]:\n",
    "            imgIds = set([img['id'] for img in res.dataset['images']]) & set([ann['image_id'] for ann in anns])\n",
    "            res.dataset['images'] = [img for img in res.dataset['images'] if img['id'] in imgIds]\n",
    "            for id, ann in enumerate(anns):\n",
    "                ann['id'] = id+1\n",
    "        elif 'bbox' in anns[0] and not anns[0]['bbox'] == []:\n",
    "            res.dataset['categories'] = copy.deepcopy(self.dataset['categories'])\n",
    "            for id, ann in enumerate(anns):\n",
    "                bb = ann['bbox']\n",
    "                x1, x2, y1, y2 = [bb[0], bb[0]+bb[2], bb[1], bb[1]+bb[3]]\n",
    "                if not 'segmentation' in ann:\n",
    "                    ann['segmentation'] = [[x1, y1, x1, y2, x2, y2, x2, y1]]\n",
    "                ann['area'] = bb[2]*bb[3]\n",
    "                ann['id'] = id+1\n",
    "                ann['iscrowd'] = 0\n",
    "        elif 'segmentation' in anns[0]:\n",
    "            res.dataset['categories'] = copy.deepcopy(self.dataset['categories'])\n",
    "            for id, ann in enumerate(anns):\n",
    "                # now only support compressed RLE format as segmentation results\n",
    "                ann['area'] = maskUtils.area(ann['segmentation'])\n",
    "                if not 'bbox' in ann:\n",
    "                    ann['bbox'] = maskUtils.toBbox(ann['segmentation'])\n",
    "                ann['id'] = id+1\n",
    "                ann['iscrowd'] = 0\n",
    "        elif 'keypoints' in anns[0]:\n",
    "            res.dataset['categories'] = copy.deepcopy(self.dataset['categories'])\n",
    "            for id, ann in enumerate(anns):\n",
    "                s = ann['keypoints']\n",
    "                x = s[0::3]\n",
    "                y = s[1::3]\n",
    "                x0,x1,y0,y1 = np.min(x), np.max(x), np.min(y), np.max(y)\n",
    "                ann['area'] = (x1-x0)*(y1-y0)\n",
    "                ann['id'] = id + 1\n",
    "                ann['bbox'] = [x0,y0,x1-x0,y1-y0]\n",
    "        if self.verbose:\n",
    "            logger.info('DONE (t={:0.2f}s)'.format(time.time()- tic))\n",
    "\n",
    "        res.dataset['annotations'] = anns\n",
    "        res.createIndex()\n",
    "        return res        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e2f970-19aa-4559-a0c6-098e845b908f",
   "metadata": {},
   "source": [
    "## Coco dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0add8d1a-ba05-4a11-99b1-c3139e0a327b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from avcv.visualize import bbox_visualize\n",
    "class CocoDataset:\n",
    "    def __init__(self, gt, img_dir=None, pred=None, verbose=False):\n",
    "        if img_dir is None:\n",
    "            assert isinstance(gt, str) and '/annotations/' in gt\n",
    "            img_dir = gt.split('/annotations/')[0]+'/images'\n",
    "            if verbose:\n",
    "                logger.warning(f'Img dir is not set, set to :{img_dir}')\n",
    "            assert osp.isdir(img_dir)\n",
    "            \n",
    "        if isinstance(gt, COCO):\n",
    "            gt = gt.dataset\n",
    "        self.gt = AvCOCO(gt, verbose=verbose)\n",
    "\n",
    "        if isinstance(pred, str):\n",
    "            pred = mmcv.load(pred)\n",
    "\n",
    "        self.pred = self.gt.loadRes(pred) if pred is not None else None\n",
    "\n",
    "        self.img_dir = img_dir\n",
    "        self.img_ids = [_['id'] for _ in self.gt.imgs.values()]\n",
    "\n",
    "    def imread(self, img_id, channel_order='bgr'):\n",
    "        im = self.gt.imgs[img_id]\n",
    "        img_path = osp.join(self.img_dir,im['file_name'])\n",
    "        assert osp.exists(img_path), img_path\n",
    "        return mmcv.imread(img_path, channel_order=channel_order)\n",
    "\n",
    "    def visualize(self, img_id=None,  mode='gt', dpi=100, \n",
    "        show=False, anns=None, color='green', img=None, score_thr=0.3, box_color=None):\n",
    "        if img_id is None:\n",
    "            img_id = np.random.choice(self.img_ids)\n",
    "            logger.info(f'Random visualize img_id={img_id}')\n",
    "        if img is None:\n",
    "            img= self.imread(img_id)\n",
    "\n",
    "        if mode=='pred':\n",
    "            assert self.pred is not None\n",
    "\n",
    "        CLASSES = {cat_id:cat['name'] for cat_id, cat in self.gt.cats.items()}\n",
    "        im = self.gt.imgs[img_id]\n",
    "        source = self.pred if mode == 'pred' else self.gt\n",
    "\n",
    "        if anns is None:\n",
    "            anns  = source.loadAnns(source.getAnnIds(im['id']))\n",
    "\n",
    "        bboxes = []\n",
    "        lables = []\n",
    "        scores = []\n",
    "        for ann in anns:\n",
    "            x1,y1,w,h = [int(_) for _ in ann['bbox']]\n",
    "            x2 = x1+w\n",
    "            y2 = y1+h\n",
    "            scores.append(ann.get('score', 1))\n",
    "            bboxes.append([x1,y1,x2,y2])\n",
    "            lables.append(ann['category_id'])\n",
    "\n",
    "        bboxes = np.array(bboxes)\n",
    "        lables = np.array(lables)\n",
    "\n",
    "        if len(bboxes):\n",
    "            \n",
    "            img = bbox_visualize(img, bboxes, scores, lables, score_thr, CLASSES, box_color=box_color)\n",
    "#             img = mmcv.visualization.imshow_det_bboxes(img, bboxes, \n",
    "#                 lables, CLASSES, show=False, bbox_color=color, text_color=color, \n",
    "#                 score_thr=score_thr)\n",
    "        if show:\n",
    "            av_show(img[...,::-1], dpi=dpi)\n",
    "        return img\n",
    "\n",
    "    def load_anns(self, img_id, source=None):\n",
    "        if source is None:\n",
    "            source = self.gt\n",
    "        anns = source.loadAnns(source.getAnnIds(img_id))\n",
    "        return anns\n",
    "\n",
    "    def evaluate(self, *args, **kwargs):\n",
    "        cocoEval = COCOeval(self.gt, self.pred, 'bbox')\n",
    "        cocoEval.evaluate()\n",
    "        cocoEval.accumulate()\n",
    "        cocoEval.summarize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d43b1f",
   "metadata": {},
   "source": [
    "### BBox utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a8c76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_bboxes(anns,category_ids,\n",
    "               mode='xywh',\n",
    "               dtype=np.float32,\n",
    "               score_thr=None, with_score=False):\n",
    "    bboxes = []\n",
    "    for ann in anns:\n",
    "        if category_ids is not None and  not ann['category_id'] in category_ids: continue\n",
    "        if score_thr is not None and ann.get('score', False):\n",
    "            if ann['score'] < score_thr:\n",
    "                continue\n",
    "        x, y, w, h = ann['bbox']\n",
    "        \n",
    "        score = ann.get('score', 1)\n",
    "        if mode == 'xywh':\n",
    "            bboxes.append([x, y, w, h, score])\n",
    "        elif mode == 'xyxy':\n",
    "            bboxes.append([x, y, x + w, y + h, score])\n",
    "        elif mode == 'cxcywh':\n",
    "            cx = x + w / 2\n",
    "            cy = y + h / 2\n",
    "            bboxes.append([cx, cy, w, h, score])\n",
    "        else:\n",
    "            raise NotImplemented\n",
    "    bboxes = np.array(bboxes).reshape([-1, 5])\n",
    "    if not with_score:\n",
    "        bboxes = bboxes[:,:4]\n",
    "        \n",
    "    if dtype is not None:\n",
    "        bboxes = bboxes.astype(dtype)\n",
    "    return bboxes\n",
    "\n",
    "\n",
    "def get_overlap_rate(boxA, boxB):\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "    iou = interArea / float(boxAArea)\n",
    "    return iou\n",
    "\n",
    "\n",
    "def bbox_expand(bb, im_h, im_w, r=1.25):\n",
    "    x,y,w,h = bb\n",
    "    cx = x+w/2\n",
    "    cy = y+h/2\n",
    "    h*=r\n",
    "    w*=r\n",
    "    \n",
    "    x1 = cx-w/2\n",
    "    y1 = cy-h/2\n",
    "    x2 = x1+w\n",
    "    y2 = y1+h\n",
    "    \n",
    "    x1 = max(0, x1)\n",
    "    y1 = max(0, y1)\n",
    "    x2 = min(im_w, x2)\n",
    "    y2 = min(im_h, y2)\n",
    "    \n",
    "    return x1, y1, x2-x1, y2-y1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9517518",
   "metadata": {},
   "source": [
    "## DiagnoseCoco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecd78cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DiagnoseCoco(CocoDataset):\n",
    "    COLORS = dict(\n",
    "        TP=(0, 255, 0),\n",
    "        FN=(0, 0, 255), # Undetected GT\n",
    "        FP=(0,255,255), # Wrong detection\n",
    "    )\n",
    "\n",
    "    def find_false_samples(self, img_id, score_thr=0.05, visualize=True):\n",
    "        from mmcv.ops import bbox_overlaps\n",
    "        assert self.gt is not None\n",
    "        assert self.pred is not None\n",
    "        pred_anns = [ann for ann in self.pred.loadAnns(self.pred.getAnnIds(img_id)) if ann['score']>score_thr]\n",
    "        gt_anns = self.gt.loadAnns(self.gt.getAnnIds(img_id))\n",
    "\n",
    "        pred_bboxes = get_bboxes(pred_anns,None , mode='xyxy')\n",
    "        pred_bboxes = torch.from_numpy(pred_bboxes).cuda().float()\n",
    "\n",
    "        gt_bboxes = get_bboxes(gt_anns, None,mode='xyxy')\n",
    "        gt_bboxes = torch.from_numpy(gt_bboxes).cuda().float()\n",
    "        with torch.no_grad():\n",
    "            ious = bbox_overlaps(pred_bboxes, gt_bboxes).cpu().numpy()\n",
    "        mapping_gt_pred = np.where(ious>0)\n",
    "\n",
    "        result = dict(tp=[], fn=[], fp=[])\n",
    "\n",
    "        gt_ids = list(range(len(gt_anns)))\n",
    "        pred_ids = list(range(len(pred_anns)))\n",
    "        for pred_id, gt_id in zip(*mapping_gt_pred):\n",
    "            if gt_anns[gt_id]['category_id'] == pred_anns[pred_id]['category_id']:\n",
    "                result['tp'].append(pred_anns[pred_id])\n",
    "                if gt_id in gt_ids:\n",
    "                    gt_ids.remove(gt_id)\n",
    "                if pred_id in pred_ids:\n",
    "                    pred_ids.remove(pred_id)\n",
    "\n",
    "\n",
    "        result['fp'] = [pred_anns[i] for i in  pred_ids]\n",
    "        result['fn'] = [gt_anns[i] for i in gt_ids]\n",
    "        if visualize:\n",
    "            vis_img = self.visualize(img_id, anns=result['fn'], color=self.COLORS['FN'], show=False, box_color=self.COLORS['FN'])\n",
    "            vis_img = self.visualize(img_id,  anns=result['tp'],img=vis_img, show=False,box_color=self.COLORS['TP'])\n",
    "            vis_img = self.visualize(img_id, anns=result['fp'], dpi=150,color=self.COLORS['FP'], show=False,\n",
    "                                     img=vis_img, box_color=self.COLORS['FP'])\n",
    "            vis_img = vis_img[...,::-1].copy()\n",
    "            result['vis_img'] = vis_img\n",
    "        return result\n",
    "    \n",
    "    def imshow(self, img_id, score_thr=0.05, **show_kwargs):\n",
    "        from avcv.visualize import show\n",
    "        img = self.find_false_samples(img_id, score_thr)['vis_img']\n",
    "        show(img, **show_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e909ae4f",
   "metadata": {},
   "source": [
    "# Utils\n",
    "## Video To Coco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086617bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from avcv.utils import video_to_images, multi_thread, get_name\n",
    "import os.path as osp\n",
    "from glob import glob\n",
    "from functools import partial\n",
    "from PIL import Image\n",
    "from multiprocessing import Pool\n",
    "def _f(p):\n",
    "    img = mmcv.imread(p)\n",
    "    mmcv.imwrite(img, p.replace('.png', '.jpg'))\n",
    "    os.remove(p)\n",
    "    \n",
    "def to_jpg(img_dir):\n",
    "    paths = glob(osp.join(img_dir, '*.png'))\n",
    "    logger.info(f'Converting folder {img_dir} to jpg...')\n",
    "    with Pool(10) as p:\n",
    "        it = p.imap(_f, paths)\n",
    "        total = len(paths)\n",
    "        r = list(tqdm(it, total=total))\n",
    "\n",
    "def video_to_coco(\n",
    "    input_video,\n",
    "    test_json,\n",
    "    output_dir=None,\n",
    "    skip=1,\n",
    "    rescale=None,\n",
    "    recursive=False,\n",
    "):\n",
    "\n",
    "    assert os.path.exists(input_video), f'{input_video} does not exist'\n",
    "    try:\n",
    "        fps = mmcv.VideoReader(input_video).fps\n",
    "    except:\n",
    "        fps = None\n",
    "        \n",
    "    def path2image(path, root_dir):\n",
    "        w, h = Image.open(path).size\n",
    "        name = path.replace(root_dir, '')\n",
    "        if name.startswith('/'):\n",
    "            name = name[1:]\n",
    "        return dict(\n",
    "            file_name=name, height=h, width=w\n",
    "        )\n",
    "    \n",
    "\n",
    "    if output_dir is None:\n",
    "        name  = get_name(input_video) if not osp.isdir(input_video) else \\\n",
    "            os.path.normpath(input_video).split('/')[-1]\n",
    "        output_dir = osp.join('.cache/video_to_coco', name)\n",
    "        logger.info(f'Set output dir to->{output_dir}')\n",
    "\n",
    "    image_out_dir = osp.join(output_dir, 'images')\n",
    "\n",
    "    image_dir_name = osp.normpath(image_out_dir).split('/')[-1]\n",
    "    path_out_json = osp.join(output_dir, f'annotations/{image_dir_name}.json')\n",
    "\n",
    "    mmcv.mkdir_or_exist(osp.dirname(path_out_json))\n",
    "\n",
    "    source_type = 'dir' if osp.isdir(input_video) else 'video'\n",
    "    \n",
    "    if not osp.isdir(input_video): # IF VIDEO => EXTRACT IMAGES to image_out_dir\n",
    "        mmcv.mkdir_or_exist(image_out_dir)\n",
    "        video = mmcv.VideoReader(input_video)\n",
    "        \n",
    "\n",
    "        if rescale is not None:\n",
    "            _im = mmcv.imrescale(video[0], rescale)\n",
    "            im_h, im_w = _im.shape[:2]#int(rescale*im_h), int(rescale*im_w)\n",
    "        else:\n",
    "            im_h, im_w = video[0].shape[:2]\n",
    "\n",
    "        is_done_extracted =  len(glob(osp.join(image_out_dir, '*.jpg'))) == len(video)\n",
    "        if not is_done_extracted:\n",
    "            logger.info(f'Generating images from {source_type}: {input_video} ->  {osp.abspath(output_dir)}')\n",
    "            mmcv.mkdir_or_exist(image_out_dir)\n",
    "            cmd = f\"ffmpeg  -i {input_video} -s {im_w}x{im_h} {image_out_dir}/%06d.png\"\n",
    "            logger.info(f'Running command: {cmd}')\n",
    "            os.system(cmd)\n",
    "            to_jpg(image_out_dir)\n",
    "        else:\n",
    "            logger.info('Skip extracting video')\n",
    "        \n",
    "    else:\n",
    "        # IF FOLDER THEN CREATE SYMLINK\n",
    "        logger.info(f'Symn link {input_video}-> {image_out_dir}')\n",
    "        os.symlink(osp.abspath(input_video), osp.abspath(image_out_dir))\n",
    "        \n",
    "    paths = list(sorted(glob(osp.join(image_out_dir, '*.jpg'), recursive=recursive)))\n",
    "    paths += list(sorted(glob(osp.join(image_out_dir, '*.png'), recursive=recursive)))\n",
    "    out_dict = dict(images=[], annotations=[], meta=dict(fps=fps),\n",
    "                    categories=mmcv.load(test_json)['categories'])\n",
    "    out_dict['images'] = list(\n",
    "        map(partial(path2image, root_dir=image_out_dir), paths))\n",
    "\n",
    "    for i, image in enumerate(out_dict['images']):\n",
    "        image['id'] = i\n",
    "    mmcv.dump(out_dict, path_out_json)\n",
    "    return os.path.normpath(path_out_json), os.path.normpath(image_out_dir)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9576cf6-7034-4325-ad5e-7313784fb8d6",
   "metadata": {},
   "source": [
    "# CocoUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515cf61b-2c30-41a5-943f-9d6128a507f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def split_coco(coco, train_ratio=0.85, seed=0):\n",
    "    if isinstance(coco, dict):\n",
    "        coco = AvCOCO(coco)\n",
    "    ids = list(coco.imgs.keys())\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(ids)\n",
    "    train_n = int(len(ids)*train_ratio)\n",
    "    train_ids = ids[:train_n]\n",
    "    test_ids = ids[train_n:]\n",
    "    logger.info('Spliting ratio {} -> {} training and {} testing'.format(train_ratio, len(train_ids), len(test_ids)))\n",
    "    \n",
    "    # train_ds = coco.dataset.copy()\n",
    "    # val_ds = coco.dataset.copy()\n",
    "    def get_ds(ids):\n",
    "        out = dict(categories=coco.dataset['categories'], images=[], annotations=[])\n",
    "        for img_id in ids:\n",
    "            out['images'].append(coco.imgs[img_id])\n",
    "            out['annotations'].extend(coco.imgToAnns[img_id])\n",
    "        return out\n",
    "    return get_ds(train_ids), get_ds(test_ids)\n",
    "\n",
    "\n",
    "def concat_coco(datasets, new_root, name=None):\n",
    "    \"\"\"\n",
    "        Example:\n",
    "            concat_coco([\n",
    "                (train_ds_1, '/data/full-version-vip-pro/DMS_DB_090922/'),\n",
    "                (train_ds_2, '/data/DMS_Behavior_Detection/merge-phone-cigaret-food/images'),\n",
    "\n",
    "            ], '/data/face_food_concat/', 'train');\n",
    "        \"\"\"\n",
    "    mmcv.mkdir_or_exist(osp.join(new_root, 'annotations'))\n",
    "    out_concat = dict(\n",
    "        images=[],\n",
    "        annotations=[],\n",
    "    )\n",
    "\n",
    "    for json_path, old_img_dir in datasets:\n",
    "        dataset = AvCOCO(json_path)\n",
    "        # assert check_save_coco_dict(dataset.dataset)\n",
    "        CocoDataset(json_path, old_img_dir).visualize()\n",
    "        \n",
    "        for img_id in dataset.imgs:\n",
    "            image = dataset.imgs[img_id]\n",
    "            anns = dataset.imgToAnns[image['id']] if img_id in dataset.imgToAnns else []\n",
    "            image['id'] = len(out_concat['images'])\n",
    "            old_path = osp.join(old_img_dir, image['file_name'])\n",
    "            old_path = osp.abspath(old_path)\n",
    "            assert osp.exists(old_path), old_path\n",
    "            image['file_name'] = osp.relpath(old_path, osp.join(new_root, 'images'))\n",
    "            for ann in anns:\n",
    "                ann['image_id'] = image['id']\n",
    "                w,h = ann['bbox'][-2:]\n",
    "                ann['area'] = w*h\n",
    "                ann['id'] = len(out_concat['annotations'])\n",
    "                \n",
    "                out_concat['annotations'].append(ann)\n",
    "                \n",
    "            out_concat['images'].append(image)\n",
    "\n",
    "    out_concat['categories'] = dataset.dataset['categories']\n",
    "    if name is not None:\n",
    "        out_json_path = osp.join(new_root,f'annotations/{name}.json')\n",
    "        logger.info('Dump->{}', out_json_path)\n",
    "        check_save_coco_dict(out_concat)\n",
    "        mmcv.dump(out_concat, out_json_path)\n",
    "    return out_concat\n",
    "\n",
    "\n",
    "def check_save_coco_dict(data):\n",
    "    def check_duplicated_id(name):\n",
    "        ids = set()\n",
    "        for item in data[name]:\n",
    "            if not item['id'] in ids:\n",
    "                ids.add(item['id'])\n",
    "            else:\n",
    "                print(f'{name}, Id: {id} is duplicated, item: {item}')\n",
    "                return False\n",
    "        return True\n",
    "    if check_duplicated_id('images') and check_duplicated_id('annotations') and check_duplicated_id('categories'):\n",
    "        print('This dict is cocoly safe')\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def extract_coco(coco, img_ids):\n",
    "    if isinstance(coco, dict) or isinstance(coco, str):\n",
    "        coco = AvCOCO(coco)\n",
    "    imgs = coco.loadImgs(img_ids)\n",
    "    anns = coco.loadAnns(coco.getAnnIds(img_ids))\n",
    "    return dict(images=imgs, annotations=anns, categories=coco.dataset['categories'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078f0fa8",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5122728e",
   "metadata": {},
   "source": [
    "## CLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5768397",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@call_parse\n",
    "def v2c(input_video: Param(\"path to video\", str),\n",
    "        test_json: Param(\"path to annotation json path, to get the category\", str),\n",
    "        output_dir: Param(\"\", str) = None,\n",
    "        skip: Param(\"\", int) = 1,        rescale: Param(\"\", int) = None, recursive: Param(\"Images recursive\", bool)=False\n",
    "        ):\n",
    "    return video_to_coco(input_video, test_json, output_dir, skip, rescale=rescale, recursive=recursive)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b10d43-4897-4c9b-8a19-e9333411cc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from fastcore.all import *\n",
    "class CocoConverterFromYolo1(object):\n",
    "    \"\"\"\n",
    "        Params:\\nimage_dir: have the same structure with 'YOLO_ANNOTATION_DIR/obj_train_data'\\n\n",
    "            yolo_annotation_dir: extracted dir from cvat-yolo1.0 format\\n\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, image_dir = './images/', yolo_annotation_dir = './yolo_annotations/', image_exts=['jpg', 'png', 'jpeg']):\n",
    "        # yolo_annotation_dir = osp.normpath(yolo_annotation_dir)\n",
    "        store_attr('image_dir, yolo_annotation_dir, image_exts')\n",
    "        \n",
    "\n",
    "        \n",
    "    def get_coco_annotations(self, out_path=None):\n",
    "        \n",
    "        image_paths = []\n",
    "        for ext in self.image_exts:\n",
    "            img_paths = glob(f'{self.image_dir}**/*.{ext}')\n",
    "            image_paths.extend(img_paths)\n",
    "            \n",
    "        cat_names = [_[:-1] for _ in open(f'{self.yolo_annotation_dir}/obj.names').readlines()]\n",
    "        catname2id = {n:i+1 for i, n in enumerate(cat_names)}\n",
    "        object_dir = f'{self.yolo_annotation_dir}/obj_train_data'\n",
    "        \n",
    "        \n",
    "        out_dict = dict(images=[], annotations=[], categories=[{'id':catname2id[name], 'name':name} for name in cat_names])\n",
    "        # for image_path in tqdm(self.images):\n",
    "        def f(image_path):\n",
    "            image = dict(file_name = osp.relpath(image_path, self.image_dir), id=len(out_dict['images']))\n",
    "            txt_file_name = image['file_name'].split('.')[0]+'.txt'\n",
    "            \n",
    "            txt_path = osp.join(object_dir, txt_file_name)\n",
    "            width, height = Image.open(image_path).size\n",
    "            out_dict['images'].append(image)\n",
    "            if osp.exists(txt_path):\n",
    "                lines2 = [_[:-1] for _ in open(txt_path)]\n",
    "                for i,line in enumerate(lines2): # for loop runs for number of annotations labelled in an image\n",
    "                    line = line.split(' ')\n",
    "                    bbox_dict = {}\n",
    "                    class_id, x_yolo,y_yolo,width_yolo,height_yolo= line[0:]\n",
    "                    x_yolo,y_yolo,width_yolo,height_yolo,class_id= float(x_yolo),float(y_yolo),float(width_yolo),float(height_yolo),int(class_id)\n",
    "                    bbox_dict['id'] = len(out_dict['annotations'])\n",
    "                    bbox_dict['image_id'] = image['id']\n",
    "                    bbox_dict['category_id'] = class_id+1\n",
    "                    bbox_dict['iscrowd'] = 0 # There is an explanation before\n",
    "                    h,w = abs(height_yolo*height),abs(width_yolo*width)\n",
    "                    bbox_dict['area']  = h * w\n",
    "                    x_coco = round(x_yolo*width -(w/2))\n",
    "                    y_coco = round(y_yolo*height -(h/2))\n",
    "                    if x_coco <0: #check if x_coco extends out of the image boundaries\n",
    "                        x_coco = 1\n",
    "                    if y_coco <0: #check if y_coco extends out of the image boundaries\n",
    "                        y_coco = 1\n",
    "                    bbox_dict['bbox'] = [x_coco,y_coco,w,h]\n",
    "                    bbox_dict['segmentation'] = [[x_coco,y_coco,x_coco+w,y_coco, x_coco+w, y_coco+h, x_coco, y_coco+h]]\n",
    "                    out_dict['annotations'].append(bbox_dict)\n",
    "        multi_thread(f, image_paths, max_workers=None)\n",
    "        \n",
    "        self.cc = CocoDataset(out_dict, self.image_dir)\n",
    "        if out_path is not None:\n",
    "            mmcv.dump(out_dict, out_path)\n",
    "        return out_dict\n",
    "    \n",
    "    def visualize(self, n=9, ret=False):\n",
    "        images = []\n",
    "        for img_id in np.random.choice(self.cc.img_ids, n):\n",
    "            images.append(self.cc.visualize(img_id))\n",
    "        # plt.plot(images, mxn=[3,3])\n",
    "        plot_images(images, mxn=(3,3))\n",
    "        if ret:\n",
    "            return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cc48b7-24d4-4079-b892-084bf3361587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### CocoConverterFromYolo1\n",
       "\n",
       ">      CocoConverterFromYolo1 (image_dir='./images/',\n",
       ">                              yolo_annotation_dir='./yolo_annotations/',\n",
       ">                              image_exts=['jpg','png','jpeg'])\n",
       "\n",
       "        Params:"
      ],
      "text/plain": [
       "<nbdev.showdoc.BasicMarkdownRenderer at 0x7fc354d455e0>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(CocoConverterFromYolo1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0beb94f5-ad61-44f9-962a-97d318d8670f",
   "metadata": {},
   "source": [
    "# BUILD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc175984",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nbdev_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e9b58d-934b-44fc-a2ba-34cc6a02ee07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5d018e-ab49-4933-9cad-b00c1ba5ab61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846bd7b4-7c62-47fe-86cb-8c71a64d4af8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
