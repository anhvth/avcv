{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n"
     ]
    }
   ],
   "source": [
    "# export\n",
    "import os\n",
    "from glob import glob\n",
    "import os\n",
    "import cv2\n",
    "import os.path as osp\n",
    "from tqdm import tqdm\n",
    "import mmcv\n",
    "from fastcore.script import call_parse, Param\n",
    "from avcv.process import multi_thread\n",
    "\n",
    "def get_name(path):\n",
    "    path = osp.basename(path).split('.')[:-1]\n",
    "    return '.'.join(path)\n",
    "\n",
    "\n",
    "def find_contours(thresh):\n",
    "    \"\"\"\n",
    "        Get contour of a binary image\n",
    "            Arguments:\n",
    "                thresh: binary image\n",
    "            Returns:\n",
    "                Contours: a list of contour\n",
    "                Hierarchy:\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE,\n",
    "                                            cv2.CHAIN_APPROX_SIMPLE)\n",
    "        return contours, hierarchy[0]\n",
    "    except:\n",
    "        return None, None\n",
    "\n",
    "\n",
    "@call_parse\n",
    "def download_file_from_google_drive(id_or_link: Param(\"Link or file id\"), destination: Param(\"Path to the save file\")):\n",
    "    if \"https\" in id_or_link:\n",
    "        x = id_or_link\n",
    "        id = x.split(\"/\")[x.split(\"/\").index(\"d\")+1]\n",
    "    else:\n",
    "        id = id_or_link\n",
    "    print(\"Download from id:\", id)\n",
    "    import requests\n",
    "\n",
    "    def get_confirm_token(response):\n",
    "        for key, value in response.cookies.items():\n",
    "            if key.startswith('download_warning'):\n",
    "                return value\n",
    "\n",
    "        return None\n",
    "\n",
    "    def save_response_content(response, destination):\n",
    "        CHUNK_SIZE = 32768\n",
    "\n",
    "        with open(destination, \"wb\") as f:\n",
    "            for chunk in response.iter_content(CHUNK_SIZE):\n",
    "                if chunk:  # filter out keep-alive new chunks\n",
    "                    f.write(chunk)\n",
    "\n",
    "    URL = \"https://docs.google.com/uc?export=download\"\n",
    "\n",
    "    session = requests.Session()\n",
    "\n",
    "    response = session.get(URL, params={'id': id}, stream=True)\n",
    "    token = get_confirm_token(response)\n",
    "\n",
    "    if token:\n",
    "        params = {'id': id, 'confirm': token}\n",
    "        response = session.get(URL, params=params, stream=True)\n",
    "\n",
    "    save_response_content(response, destination)\n",
    "    print(\"Done ->\", destination)\n",
    "    return osp.abspath(destination)\n",
    "\n",
    "\n",
    "def mkdir(path):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "\n",
    "def put_text(image, pos, text, color=(255, 255, 255)):\n",
    "    return cv2.putText(image, text, pos, cv2.FONT_HERSHEY_SIMPLEX, 1.0,\n",
    "                       color, 2)\n",
    "\n",
    "\n",
    "def images_to_video(\n",
    "        images,\n",
    "        out_path=None,\n",
    "        fps:int= 30,\n",
    "        no_sort= False,\n",
    "        max_num_frame= 10e12,\n",
    "        resize_rate = 1,\n",
    "        with_text = False,\n",
    "        text_is_date= False,\n",
    "        verbose=True,\n",
    "        ):\n",
    "\n",
    "    if out_path is None:\n",
    "        assert isinstance(images, str), \"No out_path specify, you need to input a string to a directory\"\n",
    "        out_path = images+'.mp4'\n",
    "    if isinstance(images, str) and os.path.isdir(images):\n",
    "        from glob import glob\n",
    "        images = glob(os.path.join(images, \"*.jpg\")) + \\\n",
    "            glob(os.path.join(images, \"*.png\"))+glob(os.path.join(images, \"*.jpeg\"))\n",
    "\n",
    "    imgs = []\n",
    "\n",
    "    def get_num(s):\n",
    "        try:\n",
    "            s = os.path.basename(s)\n",
    "            num = int(''.join([c for c in s if c.isdigit()]))\n",
    "        except:\n",
    "            num = s\n",
    "        return num\n",
    "    \n",
    "    def f(img_or_path):\n",
    "        if isinstance(img_or_path, str):\n",
    "            name = os.path.basename(img_or_path)\n",
    "            img = mmcv.imread(img_or_path)\n",
    "            img = cv2.resize(img, output_size)\n",
    "            assert img is not None, img_or_path\n",
    "            if with_text:\n",
    "                if text_is_date:\n",
    "                    from datetime import datetime\n",
    "                    name = name.split('.')[0].split('_')\n",
    "                    f = float('{}.{}'.format(*name))\n",
    "                    name = str(datetime.fromtimestamp(f))\n",
    "                img = put_text(img, (20, 20), name)\n",
    "        else:\n",
    "            img = img_or_path\n",
    "        return img\n",
    "\n",
    "\n",
    "    if not no_sort and isinstance(images[0], str):\n",
    "        images = list(sorted(images, key=get_num))\n",
    "\n",
    "    max_num_frame = int(max_num_frame)\n",
    "    max_num_frame = min(len(images), max_num_frame)\n",
    "\n",
    "    h, w = mmcv.imread(images[0]).shape[:2]\n",
    "    output_size = (int(w*resize_rate), int(h*resize_rate))\n",
    "    if out_path.endswith('.mp4'):\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "        out = cv2.VideoWriter(out_path, fourcc, fps, output_size)\n",
    "    elif out_path.endswith('.avi'):\n",
    "        out = cv2.VideoWriter(out_path, cv2.VideoWriter_fourcc(*'DIVX'), fps, output_size)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    images = images[:max_num_frame]\n",
    "\n",
    "    images = multi_thread(f, images, desc='Reading images', verbose=verbose)\n",
    "    if verbose:\n",
    "        print(\"Write video, output_size:\", output_size)\n",
    "        pbar = mmcv.ProgressBar(len(images))\n",
    "    for img in images:\n",
    "        img = cv2.resize(img, output_size)\n",
    "        out.write(img)\n",
    "        if verbose:\n",
    "            pbar.update()\n",
    "    out.release()\n",
    "    \n",
    "def get_paths(directory, input_type='png', sort=True):\n",
    "    \"\"\"\n",
    "        Get a list of input_type paths\n",
    "        params args:\n",
    "        return: a list of paths\n",
    "    \"\"\"\n",
    "    paths = glob(os.path.join(directory, '*.{}'.format(input_type)))\n",
    "    if sort:\n",
    "        paths = list(sorted(paths))\n",
    "    print('Found and sorted {} files {}'.format(len(paths), input_type))\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@call_parse\n",
    "def av_i2v(\n",
    "            images: Param(\"Path to the images folder or list of images\"),\n",
    "            out_path: Param(\"Output output video path\", str)=None,\n",
    "            fps: Param(\"Frame per second\", int) = 30,\n",
    "            no_sort: Param(\"Sort images\", bool) = False,\n",
    "            max_num_frame: Param(\"Max num of frame\", int) = 10e12,\n",
    "            resize_rate: Param(\"Resize rate\", float) = 1,\n",
    "            with_text: Param(\"Add additional index to image when writing vidoe\", bool) = False,\n",
    "            text_is_date: Param(\"Add additional index to image when writing vidoe\", bool) = False,\n",
    "            verbose:Param(\"Print...\", bool)=True,\n",
    "        ):\n",
    "\n",
    "    return images_to_video(images, out_path, fps,\n",
    "                           no_sort, max_num_frame, resize_rate, with_text,\n",
    "                           text_is_date,verbose,\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_to_images(input_video, output_dir=None, skip=1):\n",
    "    \"\"\"\n",
    "        Extract video to image:\n",
    "            inputs:\n",
    "                input_video: path to video\n",
    "                output_dir: default is set to video name\n",
    "    \"\"\"\n",
    "    import cv2\n",
    "    import os\n",
    "    import concurrent\n",
    "    from imutils.video import count_frames\n",
    "    if output_dir is None:\n",
    "        output_dir = input_video.split('.')[0]\n",
    "        print('Set output_dir =',output_dir)\n",
    "    \n",
    "    skip = int(skip)\n",
    "    # Read the video from specified path\n",
    "    cam = cv2.VideoCapture(input_video)\n",
    "    total_frames = count_frames(input_video)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    # frame\n",
    "    currentframe = 0\n",
    "    # while(True):\n",
    "    with concurrent.futures.ProcessPoolExecutor() as e:\n",
    "        f_results = []\n",
    "        for current_frame in range(0, total_frames, skip):\n",
    "            # reading from frame\n",
    "            ret,frame = cam.read()\n",
    "\n",
    "            if ret:\n",
    "                # if video is still left continue creating images\n",
    "                name =  os.path.join(output_dir,f'{current_frame:05d}' + '.jpg')\n",
    "                if currentframe % skip == 0:\n",
    "                    f_results.append(e.submit(cv2.imwrite, name, frame))\n",
    "            else:\n",
    "                break\n",
    "        for result in tqdm(concurrent.futures.as_completed(f_results)):\n",
    "            pass\n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "#export\n",
    "@call_parse\n",
    "def av_v2i(input_video:Param(\"\", str), output_dir:Param(\"\", str)=None, skip:Param(\"\", int)=1):\n",
    "    return video_to_images(input_video, output_dir, skip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLI examples\n",
    "+ Download file given a google link\n",
    "\n",
    "        gdown --help\n",
    "        gdown \"https://drive.google.com/file/d/1xOb92Yx3hoOsMsAiI2mnkcyoQatRQNBf/view?usp=sharing\" test.mp3\n",
    "        \n",
    "This should return a openable mp3 file\n",
    "+ Compose a video given a folder of images        \n",
    "\n",
    "        i2v --help\n",
    "        i2v PATH_TO_DIR out.mp4\n",
    "\n",
    "+ Extract images given a video\n",
    "\n",
    "        v2i --help # helper\n",
    "        v2i test.mp4 test-img/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from mmcv import Timer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "class TimeLoger:\n",
    "    def __init__(self):\n",
    "        self.timer = Timer()\n",
    "        self.time_dict = dict()\n",
    "\n",
    "    def start(self):\n",
    "        self.timer.start()\n",
    "\n",
    "    def update(self, name):\n",
    "        # assert not name in self.time_dict\n",
    "        duration = self.timer.since_last_check()\n",
    "        if name in self.time_dict:\n",
    "            self.time_dict[name].append(duration)\n",
    "        else:\n",
    "            self.time_dict[name] = [duration]\n",
    "\n",
    "    def __str__(self):\n",
    "        total_time = np.sum([np.sum(v) for v in self.time_dict.values()])\n",
    "        s = f\"------------------Time Loger Summary : Total {total_time:0.2f} ---------------------:\\n\"\n",
    "        for k, v in self.time_dict.items():\n",
    "            average = np.mean(v)\n",
    "            times = len(v)\n",
    "            percent = np.sum(v)*100/total_time\n",
    "            # print()\n",
    "            s += f'\\t\\t{k}:  \\t\\t{percent:0.2f}% ({average:0.4f}s) | Times: {times} \\n'\n",
    "        # print('-----------------------------------------------------------')\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------Time Loger Summary : Total 2.00 ---------------------:\n",
      "\t\tan sang:  \t\t0.00% (0.0000s) | Times: 1 \n",
      "\t\tan trua:  \t\t100.00% (2.0023s) | Times: 1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "import time\n",
    "\n",
    "t = TimeLoger()\n",
    "\n",
    "\n",
    "t.update('an sang')\n",
    "time.sleep(2)\n",
    "t.update('an trua')\n",
    "\n",
    "t.time_dict\n",
    "\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memoize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import xxhash\n",
    "import pickle\n",
    "\n",
    "def identify(x):\n",
    "    '''Return an hex digest of the input'''\n",
    "    return xxhash.xxh64(pickle.dumps(x), seed=0).hexdigest()\n",
    "\n",
    "\n",
    "def memoize(func):\n",
    "    import os\n",
    "    import pickle\n",
    "    from functools import wraps\n",
    "\n",
    "    import xxhash\n",
    "\n",
    "    '''Cache result of function call on disk\n",
    "    Support multiple positional and keyword arguments'''\n",
    "    @wraps(func)\n",
    "    def memoized_func(*args, **kwargs):\n",
    "        cache_dir = 'cache'\n",
    "        try:\n",
    "            import inspect\n",
    "            func_id = identify((inspect.getsource(func), args, kwargs))\n",
    "            cache_path = os.path.join(cache_dir, func.__name__+'_'+func_id)\n",
    "\n",
    "            if (os.path.exists(cache_path) and\n",
    "                    not func.__name__ in os.environ and\n",
    "                    not 'BUST_CACHE' in os.environ):\n",
    "                result = pickle.load(open(cache_path, 'rb'))\n",
    "            else:\n",
    "                result = func(*args, **kwargs)\n",
    "                os.makedirs(cache_dir, exist_ok=True)\n",
    "                pickle.dump(result, open(cache_path, 'wb'))\n",
    "            return result\n",
    "        except (KeyError, AttributeError, TypeError):\n",
    "            return func(*args, **kwargs)\n",
    "    return memoized_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: nbdev_build_lib\n"
     ]
    }
   ],
   "source": [
    "!cd ~/avcv/nbs && nbdev_build_lib && pip install -e ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
